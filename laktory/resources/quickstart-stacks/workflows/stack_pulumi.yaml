name: workflows
organization: my_organization  # Will be used as Pulumi organization
description: Lakehouse - Workflows
backend: pulumi

# Databricks Provider Configuration
pulumi:
  config:
    databricks:host: ${vars.DATABRICKS_HOST}
    databricks:token: ${vars.DATABRICKS_TOKEN}

# List of Resources to deploy
resources:

  # DBFS Files: Stock prices data json file
  databricks_dbfsfiles: !use resources/dbfsfiles.yaml

  # Python package (lake)
  databricks_pythonpackages: !use resources/pythonpackages.yaml

  # Notebooks for jobs and pipelines
  databricks_notebooks: !use resources/notebooks.yaml

  # Simple sample job
  databricks_jobs:
    job-hello: !use resources/job-hello.yaml

  # Laktory Sample Pipelines
  #   - Deployed resources depend on selected orchestrator
  #   - pl-stocks-job: Deployed as a Job with SQL transformations
  #   - pl-stocks-dlt: Deployed as a Lakeflow Declarative Pipeline with spark transformations
  pipelines:
    pl-stocks-job: !use resources/pl-stocks-job.yaml
    pl-stocks-dlt: !use resources/pl-stocks-dlt.yaml

  variables:
    wheel_filepath: /Workspace${vars.workspace_laktory_root}wheels/lake-0.0.1-py3-none-any.whl

# Environment Specific Settings
environments:

  dev:
    variables:
      env: dev
      is_dev: true

  prd:
    variables:
      env: prd
      is_dev: false
