organization: okube
name: unit-testing
backend: pulumi
pulumi:
  config:
    databricks:host: ${vars.DATABRICKS_HOST}
    databricks:token: ${vars.DATABRICKS_TOKEN}
resources:
  providers:
    databricks:  # for terraform, provider name must match resource type prefix
      host: ${vars.DATABRICKS_HOST}
      token: ${vars.DATABRICKS_TOKEN}
  pipelines:
    pl-custom-name:
      variables:
        workflow_name: pl-stock-prices-ut-stack
      name: ${vars.workflow_name}
      orchestrator:
        type: DATABRICKS_DLT
        configuration:
          business_unit: ${vars.business_unit}
          workflow_name: ${vars.workflow_name}
        resource_name: dlt-custom-name
        libraries:
          - notebook:
              path: /pipelines/dlt_brz_template.py
        access_controls:
          - group_name: account users
            permission_level: CAN_VIEW
          - group_name: role-engineers
            permission_level: CAN_RUN
        options:
          provider: ${resources.databricks}
      nodes:
        - name: first_node
          source:
            path: /tmp/
            format: JSON
          dlt_template: null
  databricks_jobs:
    job-stock-prices-ut-stack:
      name: job-stock-prices-ut-stack
      clusters:
        - name: main
          spark_version: 14.0.x-scala2.12
          node_type_id: ${vars.node_type_id}
          spark_env_vars:
            AZURE_TENANT_ID: "{{secrets/azure/tenant-id}}"
            LAKTORY_WORKSPACE_ENV: ${vars.env}
      tasks:
        - task_key: ingest-metadata
          job_cluster_key: main
          notebook_task:
            notebook_path: /jobs/ingest_stock_metadata.py
          libraries:
            - pypi:
                package: laktory==0.0.27
            - pypi:
                package: yfinance
        - task_key: run-pipeline
          pipeline_task:
            pipeline_id: ${resources.dlt-custom-name.id}


    job-disabled:
        name: job-disabled
        options:
          is_enabled: False
        tasks:
          - task_key: ingest-metadata
            notebook_task:
              notebook_path: /jobs/ingest_stock_metadata.py

  databricks_warehouses:
    warehouse-external:
      lookup_existing:
        id: "d2fa41bf94858c4b"
      access_controls:
      - group_name: role-analysts
        permission_level: CAN_USE

    warehouse-disabled:
      name: disabled
      cluster_size: "X-Small"
      options:
        is_enabled: False

  databricks_notebooks:
    notebook-external:
      lookup_existing:
        path: "/Workspace/external"
      access_controls:
      - group_name: role-analysts
        permission_level: CAN_READ
  databricks_permissions:
    permissions_test:
      pipeline_id: "pipeline_123"
      access_controls:
        - user_name: user1
          permission_level: CAN_MANAGE
        - user_name: user2
          permission_level: CAN_RUN

variables:
  business_unit: laktory
  workflow_name: UNDEFINED

environments:
  dev:
    variables:
      env: dev
      is_dev: true
      node_type_id: Standard_DS3_v2
  prod:
    resources:
      pipelines:
        pl-custom-name:
          orchestrator:
            development: False
    variables:
      env: prod
      is_dev: false
      node_type_id: Standard_DS4_v2
