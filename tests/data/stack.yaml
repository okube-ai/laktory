organization: okube
name: unit-testing
backend: pulumi
pulumi:
  config:
    databricks:host: ${vars.DATABRICKS_HOST}
    databricks:token: ${vars.DATABRICKS_TOKEN}
resources:
  providers:
    databricks:  # for terraform, provider name must match resource type prefix
      host: ${vars.DATABRICKS_HOST}
      token: ${vars.DATABRICKS_TOKEN}
  pipelines:
    pl-custom-name:
      name: pl-stock-prices-ut-stack
      orchestrator: DLT
      nodes:
        - name: first_node
          source:
            path: /tmp/
          dlt_template: null
      dlt:
        resource_name: dlt-custom-name
        libraries:
          - notebook:
              path: /pipelines/dlt_brz_template.py
        access_controls:
          - group_name: account users
            permission_level: CAN_VIEW
          - group_name: role-engineers
            permission_level: CAN_RUN
        options:
          provider: ${resources.databricks}
  databricks_jobs:
    job-stock-prices-ut-stack:
      name: job-stock-prices-ut-stack
      clusters:
        - name: main
          spark_version: 14.0.x-scala2.12
          node_type_id: ${vars.node_type_id}
          spark_env_vars:
            AZURE_TENANT_ID: "{{secrets/azure/tenant-id}}"
            LAKTORY_WORKSPACE_ENV: ${vars.env}
      tasks:
        - task_key: ingest-metadata
          job_cluster_key: main
          notebook_task:
            notebook_path: /jobs/ingest_stock_metadata.py
          libraries:
            - pypi:
                package: laktory==0.0.27
            - pypi:
                package: yfinance
        - task_key: run-pipeline
          pipeline_task:
            pipeline_id: ${resources.dlt-custom-name.id}  # LAKTORY STYLE
#            pipeline_id: ${resources.dltpipelines.pl-custom-name.id}  # BUNDLES STYLE
#            pipeline_id: ${databricks_pipeline.pl-custom-name.id}  # TERRAFORM STYLE
#            pipeline_id: ${pl-custom-name.id}  # PULUMI STYLE

  databricks_warehouses:
    warehouse-external:
      lookup_existing:
        id: "d2fa41bf94858c4b"
      access_controls:
      - group_name: role-analysts
        permission_level: CAN_USE

  databricks_notebooks:
    notebook-external:
      lookup_existing:
        path: "/Workspace/external"
      access_controls:
      - group_name: role-analysts
        permission_level: CAN_READ

environments:
  dev:
    variables:
      env: dev
      is_dev: true
      node_type_id: Standard_DS3_v2
  prod:
    resources:
      pipelines:
        pl-custom-name:
          dlt:
            development: False
    variables:
      env: prod
      is_dev: false
      node_type_id: Standard_DS4_v2

